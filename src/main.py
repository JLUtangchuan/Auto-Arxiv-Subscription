#!/usr/bin/env python
# -*- encoding: utf-8 -*-
'''
@File    :   main.py
@Time    :   2022/04/29 18:09:53
@Author  :   Tang Chuan 
@Contact :   tangchuan20@mails.jlu.edu.cn
@Desc    :   è‡ªåŠ¨å‘é€é‚®ä»¶
'''

import argparse
import datetime
import json
import os
import poplib
import smtplib
import time
from email import parser
from email.header import Header
from email.mime.text import MIMEText
from collections import defaultdict

import requests
from bs4 import BeautifulSoup as bs
from openai import OpenAI
import pdb

rss_json = {
    "AI": "export.arxiv.org/rss/cs.AI",
    "CV": "export.arxiv.org/rss/cs.CV",
    "CG": "export.arxiv.org/rss/cs.CG",
    "CL": "export.arxiv.org/rss/cs.CL",
    "ML": "export.arxiv.org/rss/stat.ML"
}

# é¢„å®šä¹‰çš„é¢œè‰²æ–¹æ¡ˆ
COLOR_SCHEMES = [
    {'primary': '#FF6B6B', 'light': '#FFE5E5', 'dark': '#C92A2A'},
    {'primary': '#4ECDC4', 'light': '#D3F9F6', 'dark': '#087F8C'},
    {'primary': '#45B7D1', 'light': '#DAEDFF', 'dark': '#0C7FB0'},
    {'primary': '#96CEB4', 'light': '#E8F5EE', 'dark': '#5A9F7B'},
    {'primary': '#FECA57', 'light': '#FFF3D6', 'dark': '#F59E0B'},
    {'primary': '#A29BFE', 'light': '#E8E6FF', 'dark': '#6C5CE7'},
    {'primary': '#FD79A8', 'light': '#FFE0EC', 'dark': '#E84393'},
    {'primary': '#778BEB', 'light': '#E3E7FF', 'dark': '#546DE5'},
]

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
def init_ai_client():
    """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
    try:
        client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            # base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        return client
    except Exception as e:
        print(f"AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def process_abstract_with_ai(client, title, abstract):
    """ä½¿ç”¨AIå¤„ç†æ‘˜è¦ï¼Œç¿»è¯‘å¹¶æå–å…³é”®ä¿¡æ¯"""
    if not client:
        return abstract, "", []
    
    try:
        prompt = f"""
è¯·å¯¹ä»¥ä¸‹è®ºæ–‡è¿›è¡Œåˆ†æï¼š

æ ‡é¢˜ï¼š{title}
æ‘˜è¦ï¼ˆè‹±æ–‡ï¼‰ï¼š{abstract}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. å°†æ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡
2. æå–3-5ä¸ªæ ¸å¿ƒæŠ€æœ¯å…³é”®è¯
3. ç”¨ä¸€å¥è¯æ€»ç»“è®ºæ–‡çš„ä¸»è¦è´¡çŒ®

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
    "chinese_abstract": "ä¸­æ–‡æ‘˜è¦ç¿»è¯‘",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
    "main_contribution": "ä¸»è¦è´¡çŒ®æ€»ç»“"
}}
"""
        
        completion = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ç¿»è¯‘å’Œæå–å…³é”®ä¿¡æ¯ã€‚"},
                {"role": "user", "content": prompt},
            ],
        )
        
        # è§£æAIè¿”å›çš„ç»“æœ
        ai_response = completion.choices[0].message.content
        
        # å°è¯•è§£æJSON
        try:
            # æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                chinese_abstract = result.get('chinese_abstract', abstract)
                keywords = result.get('keywords', [])
                main_contribution = result.get('main_contribution', '')
                return chinese_abstract, main_contribution, keywords
        except:
            pass
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”
        return ai_response, "", []
        
    except Exception as e:
        print(f"AIå¤„ç†å¤±è´¥: {e}")
        return abstract, "", []

def get_arxiv_data():
    """è·å–arxivæ•°æ®ï¼ŒåŒ…å«æ ‡é¢˜ã€é“¾æ¥å’Œæ‘˜è¦ï¼Œåªè¿”å›ä»Šå¤©çš„è®ºæ–‡
    """
    dic = {}
    # è·å–ä»Šå¤©çš„æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
    today = datetime.date.today().strftime('%Y-%m-%d')
    
    for k, v in rss_json.items():
        url = 'https://' + v
        r = requests.get(url)
        soup = bs(r.text, 'xml')
        items = soup.find_all('item')
        for i in range(len(items)):
            # è·å–å‘å¸ƒæ—¥æœŸ
            pub_date = items[i].find('pubDate').text
            
            # è§£ææ—¥æœŸ
            try:
                # å°†pubDateè½¬æ¢ä¸ºdatetimeå¯¹è±¡
                # RSSæ—¥æœŸæ ¼å¼é€šå¸¸æ˜¯ç±»ä¼¼ 'Wed, 29 May 2024 00:00:00 GMT'
                pub_date_obj = datetime.datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %Z')
                # è½¬æ¢ä¸ºYYYY-MM-DDæ ¼å¼è¿›è¡Œæ¯”è¾ƒ
                pub_date_str = pub_date_obj.strftime('%Y-%m-%d')
                
                # åªä¿ç•™ä»Šå¤©çš„è®ºæ–‡
                if pub_date_str != today:
                    continue
            except ValueError:
                # å¦‚æœæ—¥æœŸè§£æå¤±è´¥ï¼Œè·³è¿‡è¯¥è®ºæ–‡
                continue
            
            title = items[i].find('title').text.split("(arXiv")[0].strip()
            link = items[i].find('link').text
            
            # è·å–æ‘˜è¦ä¿¡æ¯
            description = items[i].find('description').text
            # æ¸…ç†æ‘˜è¦æ–‡æœ¬ï¼Œå»é™¤HTMLæ ‡ç­¾
            abstract_soup = bs(description, 'html.parser')
            abstract = abstract_soup.get_text().strip()
            
            # å­˜å‚¨ä¸ºå…ƒç»„ï¼š(é“¾æ¥, åŸå§‹æ‘˜è¦)
            dic[title] = (link, abstract)
    
    print(f"å·²è·å–ä»Šå¤©({today})çš„è®ºæ–‡å…± {len(dic)} ç¯‡")
    return dic


def filter_keywords(dic, keywords):
    """è¿‡æ»¤å…³é”®è¯
    """
    print("Keyword", keywords)
    res = defaultdict(list)
    for k, v in dic.items():
        for w in keywords:
            if w.lower() in k.lower():
                # vç°åœ¨æ˜¯(link, abstract)å…ƒç»„
                res[w].append((k, v[0], v[1]))  # (title, link, abstract)
    return res

def process_papers_with_ai(filtered_papers, ai_client):
    """ä½¿ç”¨AIå¤„ç†ç­›é€‰åçš„è®ºæ–‡"""
    processed_papers = defaultdict(list)
    
    for keyword, papers in filtered_papers.items():
        for title, link, abstract in papers:
            print(f"æ­£åœ¨å¤„ç†è®ºæ–‡: {title[:50]}...")
            
            # ä½¿ç”¨AIå¤„ç†æ‘˜è¦
            chinese_abstract, main_contribution, ai_keywords = process_abstract_with_ai(
                ai_client, title, abstract
            )
            
            # å­˜å‚¨å¤„ç†åçš„ä¿¡æ¯
            processed_papers[keyword].append({
                'title': title,
                'link': link,
                'original_abstract': abstract,
                'chinese_abstract': chinese_abstract,
                'main_contribution': main_contribution,
                'ai_keywords': ai_keywords
            })
            
            # APIè°ƒç”¨é—´éš”5ç§’
            time.sleep(5)
    
    return processed_papers

def sendEmail(msg_from, msg_to, auth_id, title, content):
    """å‘é€é‚®ä»¶ç›®å‰åªæ”¯æŒqqé‚®ç®±è‡ªåŠ¨å‘é€é‚®ä»¶
    """
    msg = MIMEText(content, _subtype='html', _charset='utf-8')
    msg['Subject'] = title
    msg['From'] = msg_from
    msg['To'] = msg_to
    try:
        s = smtplib.SMTP_SSL("smtp.qq.com",465)
        s.login(msg_from, auth_id)
        s.sendmail(msg_from, msg_to, msg.as_string())
        print("å‘é€æˆåŠŸ")
    except s.SMTPException:
        print("å‘é€å¤±è´¥")
    finally:
        s.quit()


def main(args):
    # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
    ai_client = init_ai_client()
    if not ai_client:
        print("è­¦å‘Šï¼šAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹æ‘˜è¦")
    
    # è·å–arvixæœ€æ–°çš„æ–‡ç« 
    dic = get_arxiv_data()
    # è¯»å–keywordsè¿›è¡Œè¿‡æ»¤
    filtered_res = filter_keywords(dic, args.keywords)
    
    # ä½¿ç”¨AIå¤„ç†è®ºæ–‡
    if ai_client and len(filtered_res) > 0:
        print("å¼€å§‹ä½¿ç”¨AIå¤„ç†è®ºæ–‡...")
        res = process_papers_with_ai(filtered_res, ai_client)
    else:
        # å¦‚æœAIä¸å¯ç”¨ï¼Œè½¬æ¢ä¸ºæ—§æ ¼å¼
        res = {}
        for k, v in filtered_res.items():
            res[k] = []
            for title, link, abstract in v:
                res[k].append({
                    'title': title,
                    'link': link,
                    'original_abstract': abstract,
                    'chinese_abstract': abstract,
                    'main_contribution': '',
                    'ai_keywords': []
                })
    
    # å‘é€åˆ°Email
    if len(res) == 0:
        print("æ²¡æœ‰æ–°çš„æ–‡ç« ")
    else:
        # æ·»åŠ CSSæ ·å¼ï¼ˆåŒ…å«æ–°çš„AIå¤„ç†å†…å®¹æ ·å¼ï¼‰
        style = """
        <style>
            body { 
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
                line-height: 1.6; 
                background-color: #f8f9fa;
                padding: 20px;
                color: #333;
            }
            h1 { 
                color: #333; 
                text-align: center;
                margin-bottom: 30px;
            }
            /* Details å’Œ Summary æ ·å¼ */
            details {
                margin-bottom: 20px;
                border-radius: 10px;
                overflow: hidden;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                background-color: white;
            }
            details[open] summary {
                border-bottom: 2px solid rgba(255,255,255,0.3);
            }
            summary {
                padding: 15px 20px;
                cursor: pointer;
                list-style: none;
                outline: none;
                font-weight: bold;
                font-size: 18px;
                color: white;
                transition: all 0.3s ease;
            }
            summary:hover {
                opacity: 0.9;
            }
            summary::-webkit-details-marker {
                display: none;
            }
            summary::before {
                content: "â–¶ ";
                display: inline-block;
                margin-right: 10px;
                transition: transform 0.3s ease;
            }
            details[open] summary::before {
                transform: rotate(90deg);
            }
            .keyword-badge {
                float: right;
                background-color: rgba(255,255,255,0.3);
                color: white;
                padding: 5px 10px;
                border-radius: 15px;
                font-size: 14px;
                font-weight: normal;
            }
            .keyword-content {
                padding: 20px;
            }
            /* è®ºæ–‡é¡¹æ ·å¼ */
            .paper-details {
                margin-bottom: 15px;
                border: 1px solid #e0e0e0;
                border-radius: 8px;
                overflow: hidden;
                background-color: white;
            }
            .paper-summary {
                padding: 12px 15px;
                cursor: pointer;
                list-style: none;
                background-color: #f8f9fa;
                font-weight: 600;
                color: #333;
                font-size: 15px;
                line-height: 1.5;
            }
            .paper-summary:hover {
                background-color: #f0f0f0;
            }
            .paper-summary::-webkit-details-marker {
                display: none;
            }
            .paper-content {
                padding: 15px;
                background-color: white;
            }
            .main-contribution {
                background-color: #e8f4fd;
                border-left: 4px solid #1890ff;
                padding: 10px 15px;
                margin: 10px 0;
                border-radius: 0 5px 5px 0;
                font-weight: 500;
                color: #2c3e50;
            }
            .ai-keywords {
                margin: 10px 0;
            }
            .ai-keyword-tag {
                display: inline-block;
                background-color: #52c41a;
                color: white;
                padding: 4px 8px;
                border-radius: 12px;
                font-size: 12px;
                margin: 2px 4px 2px 0;
                font-weight: 500;
            }
            .paper-abstract { 
                margin: 10px 0;
                color: #666;
                text-align: justify;
                padding: 15px;
                background-color: #f8f9fa;
                border-radius: 5px;
                font-size: 14px;
                line-height: 1.8;
                border-left: 3px solid #ddd;
            }
            .chinese-abstract {
                background-color: #f0f8f0;
                border-left: 3px solid #52c41a;
            }
            .original-abstract {
                background-color: #f8f8f8;
                border-left: 3px solid #999;
            }
            .paper-link { 
                margin-top: 10px;
                text-align: right;
            }
            a { 
                text-decoration: none; 
                font-weight: 500;
                padding: 5px 15px;
                border-radius: 4px;
                display: inline-block;
                color: white;
            }
            a:hover { 
                opacity: 0.8;
            }
            .abstract-label {
                font-weight: bold;
                color: #555;
                margin-bottom: 5px;
                font-size: 13px;
                text-transform: uppercase;
                letter-spacing: 0.5px;
            }
            .ai-badge {
                background-color: #722ed1;
                color: white;
                padding: 2px 8px;
                border-radius: 10px;
                font-size: 11px;
                margin-left: 8px;
            }
        </style>
        """
        
        main_html = []
        
        for idx, (k, papers) in enumerate(res.items()):
            # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ†é…é¢œè‰²
            color_scheme = COLOR_SCHEMES[idx % len(COLOR_SCHEMES)]
            
            paper_html = []
            for paper in papers:
                # æ„å»ºAIå…³é”®è¯æ ‡ç­¾
                ai_keywords_html = ""
                if paper['ai_keywords']:
                    keyword_tags = [f'<span class="ai-keyword-tag">{kw}</span>' for kw in paper['ai_keywords']]
                    ai_keywords_html = f'<div class="ai-keywords"><strong>ğŸ·ï¸ AIæå–å…³é”®è¯ï¼š</strong>{" ".join(keyword_tags)}</div>'
                
                # æ„å»ºä¸»è¦è´¡çŒ®éƒ¨åˆ†
                contribution_html = ""
                if paper['main_contribution']:
                    contribution_html = f'<div class="main-contribution">ğŸ’¡ <strong>ä¸»è¦è´¡çŒ®ï¼š</strong>{paper["main_contribution"]}</div>'
                
                paper_item = """
                <details class="paper-details">
                    <summary class="paper-summary">
                        {title}
                        {ai_badge}
                    </summary>
                    <div class="paper-content">
                        {contribution_html}
                        {ai_keywords_html}
                        <div class="abstract-label">ä¸­æ–‡æ‘˜è¦ (AIç¿»è¯‘)</div>
                        <div class="paper-abstract chinese-abstract">{chinese_abstract}</div>
                        <details>
                            <summary style="font-size: 12px; color: #666; padding: 5px 0; border: none; background: none;">
                                ğŸ“„ æŸ¥çœ‹åŸæ–‡æ‘˜è¦
                            </summary>
                            <div class="paper-abstract original-abstract">{original_abstract}</div>
                        </details>
                        <div class="paper-link">
                            <a href="{link}" target="_blank" style="background-color: {color_primary};">
                                Read Full Paper â†’
                            </a>
                        </div>
                    </div>
                </details>
                """.format(
                    title=paper['title'],
                    chinese_abstract=paper['chinese_abstract'],
                    original_abstract=paper['original_abstract'],
                    link=paper['link'],
                    color_primary=color_scheme['primary'],
                    contribution_html=contribution_html,
                    ai_keywords_html=ai_keywords_html,
                    ai_badge='<span class="ai-badge">AIå¢å¼º</span>' if ai_client else ''
                )
                paper_html.append(paper_item)
            
            paper_html = "\n".join(paper_html)
            
            keyword_section = """
            <details>
                <summary style="background-color: {color_primary};">
                    Keyword: {subject}
                    <span class="keyword-badge">{paper_count} papers</span>
                </summary>
                <div class="keyword-content" style="background-color: {color_light};">
                    {paper_html}
                </div>
            </details>
            """.format(
                subject=k, 
                paper_html=paper_html,
                paper_count=len(papers),
                color_primary=color_scheme['primary'],
                color_light=color_scheme['light']
            )
            main_html.append(keyword_section)
        
        main_html = "\n".join(main_html)

        today = datetime.date.today().__str__()
        content = """
        <html>
        <head>
            <meta charset="utf-8">
            {style}
        </head>
        <body>
            <h1>ğŸš€ ArXiv Daily - {today} {ai_status}</h1>
            <div style="text-align: center; margin-bottom: 20px; color: #666; font-size: 14px;">
                Click on keywords to expand papers, click on paper titles to view abstracts
                {ai_description}
            </div>
            {main_html}
        </body>
        </html>
        """.format(
            style=style, 
            today=today, 
            main_html=main_html,
            ai_status="ğŸ¤–" if ai_client else "",
            ai_description="<br><span style='color: #722ed1;'>âœ¨ æœ¬æœŸå†…å®¹ç”±AIå¢å¼ºï¼šä¸­æ–‡ç¿»è¯‘ + å…³é”®ä¿¡æ¯æå–</span>" if ai_client else ""
        )
        
        print("ç”Ÿæˆé‚®ä»¶å†…å®¹æˆåŠŸ")
        sendEmail(args.email, args.receiver, args.token, args.title, content)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='The Description')
    parser.add_argument('-e','--email', type=str, default=None, required=True, help='å‘é€é‚®ä»¶çš„é‚®ç®±')
    parser.add_argument('-t','--token', type=str, default=None, required=True, help='å‘é€é‚®ä»¶çš„é‚®ç®±çš„æˆæƒç ')
    parser.add_argument('-r','--receiver', type=str, default=None, required=True, help='æ¥æ”¶é‚®ä»¶çš„é‚®ç®±')
    parser.add_argument('-k','--keywords', nargs='+', default=None)
    args = parser.parse_args()
    args.title = "arxiv Daily"
    
    main(args)